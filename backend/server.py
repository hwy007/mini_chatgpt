import uvicorn
import os
import json
from typing import List
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from langchain_core.messages import HumanMessage

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from history import HistoryManager
# å¯¼å…¥æˆ‘ä»¬åœ¨agent.pyé‡Œé¢å†™çš„agentå¯¹è±¡
# æ³¨æ„ï¼šåœ¨é˜¶æ®µä¸€ï¼ŒAgentæ˜¯é™æ€çš„ï¼Œæ‰€ä»¥ç›´æ¥å¯¼å…¥å¯¹è±¡å³å¯
from agent import agent as static_agent

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# 2. åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="Mini ChatGPT Backend", version="1.0 (MVP)")

# 3. é…ç½®CORS(è·¨åŸŸèµ„æºå…±äº«)
# å…è®¸å‰ç«¯(é€šå¸¸åœ¨ localhost:3000 æˆ– 5173)è®¿é—®æ­¤åç«¯
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ç”Ÿäº§ç¯å¢ƒå»ºè®®æ›¿æ¢ä¸ºå…·ä½“å‰ç«¯åŸŸå
    allow_credientials=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)


# ==========================================
# Pydantic æ•°æ®æ¨¡å‹ (ç±»å‹å®‰å…¨)
# ==========================================

class ChatRequest(BaseModel):
    query: str      # ç”¨æˆ·çš„é—®é¢˜
    session_id: str # ä¼šè¯ID

class SessionItem(BaseModel):
    id: str
    title: str
    updated_at: int


# ==========================================
# API æ¨¡å— 1: ä¼šè¯ç®¡ç†
# ==========================================

@app.get("/sessions", response_model=List[SessionItem])
async def get_sessions():
    """è·å–å·¦ä¾§ä¾§è¾¹æ çš„ä¼šè¯åˆ—è¡¨"""
    return HistoryManager.get_all_sessions()

@app.post("/sessions")
async def create_session():
    """åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºç™½å¯¹è¯"""
    import uuid
    import time
    return {
        "id": str(uuid.uuid4()),
        "title": "æ–°å¯¹è¯",
        "updated_at": int(time.time())
    }

@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """åˆ é™¤æŒ‡å®šä¼šè¯"""
    HistoryManager.delete_session(session_id)
    return {
        "status": "success"
    }

@app.get("history/{session_id}")
async def get_history(session_id: str):
    """ç‚¹å‡»ä¾§è¾¹æ æ—¶ï¼ŒåŠ è½½è¯¥ä¼šè¯çš„å†å²æ¶ˆæ¯"""
    return HistoryManager(session_id).get_full_history()


# ==========================================
# API æ¨¡å— 2: æ ¸å¿ƒæµå¼å¯¹è¯ (SSE)
# ==========================================

def format_sse(event_type: str, data: dict):
    """è¾…åŠ©å‡½æ•°ï¼šå°è£…SSEæ¶ˆæ¯æ ¼å¼"""
    # ensure_ascii=Fasle ä¿è¯ä¸­æ–‡æ­£å¸¸ä¼ è¾“
    return f"data: {json.dumps({'type': event_type, 'data': data}, ensure_ascii=False)}\n\n"

@app.post("/chat_stream")
async def chat_stream(request: ChatRequest):
    """
    æ ¸å¿ƒå¯¹è¯æ¥å£ï¼šæ¥æ”¶ç”¨æˆ·é—®é¢˜ -> è°ƒç”¨Agent -> æµå¼è¿”å›ç»“æœ
    """

    # 1. å‡†å¤‡å†å²ä¸Šä¸‹æ–‡
    history_mgr = HistoryManager(request.session_id)
    # è¯»å–æœ€è¿‘ 40 æ¡è®°å½•ä½œä¸ºçŸ­æœŸè®°å½•
    history_messages = HistoryManager.load_messages(limit=40)
    # æ‹¼æ¥å½“å‰ç”¨æˆ·é—®é¢˜
    input_messages = history_messages + [HumanMessage(content=request.query)]

    # 2. å®šä¹‰å¼‚æ­¥ç”Ÿæˆå™¨(æ ¸å¿ƒé€»è¾‘)
    async def event_generator():
        final_answer = ""
        try:
            print(f"ğŸ”„ [server] Session {request.session_id} å¼€å§‹å¤„ç†: {request.query[:20]}...")

            # è°ƒç”¨Agentçš„astream_eventsæ–¹æ³•ï¼Œç›‘å¬å†…éƒ¨äº‹ä»¶
            # version="v2"æ˜¯LangChainæ¨èçš„ç¨³å®šç‰ˆäº‹ä»¶æµæ ¼å¼
            async for event in static_agent.astream_events(
                {"messages": input_messages},
                version="v2"
            ):
                kind = event["event"]
                name = event.get("name", "")

                # --- æƒ…å†µ A: æ¨¡å‹æ­£åœ¨ç”Ÿæˆæ–‡æœ¬ (æ‰“å­—æœºæ•ˆæœ) ---
                if kind == "on_chat_model_stream" or kind == "on_llm_stream":
                    chunk = event["data"].get("chunk")
                    content = ""
                    # å…¼å®¹ä¸åŒ chunk æ ¼å¼
                    if hasattr(chunk, "content"):
                        content = chunk.content
                    elif isinstance(chunk, dict):
                        content = chunk.get("content", "")
                    if content:
                        final_answer += content
                        # æ¨åŠ¨tokenäº‹ä»¶ç»™å‰ç«¯
                        yield format_sse("token", {"content": content})
                
                # --- æƒ…å†µ B: å·¥å…·å¼€å§‹è°ƒç”¨ (å±•ç¤º Loading) ---
                elif kind == "on_tool_start":
                    print(f"ğŸ›  [Tool Start] {name}")
                    yield format_sse("tool_start", {
                        "tool_name": name,
                        "input": event["data"].get("input")
                    })

                # --- æƒ…å†µ C: å·¥å…·è°ƒç”¨ç»“æŸ (å±•ç¤ºç»“æœ) ---
                elif kind == "on_tool_end":
                    print(f"âœ… [Tool End] {name}")
                    # å¤„ç†è¾“å‡ºæ•°æ®ï¼Œé˜²æ­¢JSONåºåˆ—åŒ–é”™è¯¯
                    raw_output = event["data"].get("output")
                    output_str = str(raw_output)
                    if hasattr(raw_output, "content"):
                        output_str = raw_output.content
                    
                    yield format_sse("tool_end", {
                        "tool_name": name,
                        "output": output_str
                    })
                
            # 3. å¯¹è¯ç»“æŸï¼Œä¿å­˜å®Œæ•´è®°å½•åˆ°ç£ç›˜
            if final_answer:
                history_mgr.save_interaction(request.query, final_answer)
                # å‘é€ç»“æŸä¿¡å·
                yield format_sse("finish", {"status": "success"})
        
        except Exception as e:
            import traceback
            print(f"âŒ [Stream Error] {traceback.format_exc()}")
            yield format_sse("error", {"message": str(e)})

    return StreamingResponse(event_generator(), media_type="text/event-stream")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Server (Port 8002)...")
    uvicorn.run(app, host="0.0.0.0", port=8002)